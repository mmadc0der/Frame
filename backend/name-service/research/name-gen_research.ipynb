{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Name Generator Research**"
      ],
      "metadata": {
        "id": "z0eNcUv9hsxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "5sNt-7orhzyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 7200\n",
        "EMBEDDING_DIM = 320"
      ],
      "metadata": {
        "id": "x1sRSAZUh5X3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_zYVHWjhacv",
        "outputId": "386d511e-6460-41c7-9c97-9f5f4d294e92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['okay youre gonna need to learn how to lie',\n",
              " 'im kidding you know how sometimes you just become this persona and you dont know how to quit',\n",
              " 'like my fear of wearing pastels',\n",
              " 'i figured youd get to the good stuff eventually',\n",
              " 'thank god if i had to hear one more story about your coiffure',\n",
              " 'me this endless blonde babble im like boring myself',\n",
              " 'do you listen to this crap',\n",
              " 'then guillermo says if you go any lighter youre gonna look like an extra on',\n",
              " 'you always been this selfish',\n",
              " 'then thats all you had to say']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "combined_sentences = list(line.strip() for line in open(\"combined_dataset.txt\", \"r\", encoding=\"utf-8\").readlines())\n",
        "combined_sentences[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenisation"
      ],
      "metadata": {
        "id": "0QJU4WtQjjAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordPiece\n",
        "from tokenizers.trainers import WordPieceTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace"
      ],
      "metadata": {
        "id": "Z4nv5aodjiJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(WordPiece(unk_token=\"[UNK]\"))\n",
        "tokenizer.pre_tokenizer = Whitespace()\n",
        "trainer = WordPieceTrainer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    min_frequency=2,\n",
        "    special_tokens=[\"[PAD]\", \"[UNK]\", \"[EOS]\", \"[EOF]\", \"[MASK]\"]\n",
        ")\n",
        "tokenizer.train(files=[\"combined_dataset.txt\"], trainer=trainer)"
      ],
      "metadata": {
        "id": "9BcT6kbZjs6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_encode = \"i have been with petronas for years i feel that petronas has performed well and made a huge profit\"\n",
        "encoded = tokenizer.encode(to_encode)\n",
        "print(\"Tokens:\", encoded.tokens)\n",
        "print(\"IDs:\", encoded.ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf1W44B2j2BW",
        "outputId": "b40de854-24b2-45d8-9de2-0e2332e6a732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['i', 'have', 'been', 'with', 'pet', '##ron', '##as', 'for', 'years', 'i', 'feel', 'that', 'pet', '##ron', '##as', 'has', 'perform', '##ed', 'well', 'and', 'made', 'a', 'huge', 'prof', '##it']\n",
            "IDs: [13, 122, 241, 126, 1270, 5100, 408, 111, 669, 13, 64, 86, 1270, 5100, 408, 381, 2897, 68, 343, 72, 534, 5, 2787, 1824, 74]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer_decode(tokens: list [str]) -> str:\n",
        "  return ' '.join(tokens).replace(' ##', '')\n",
        "\n",
        "tokenizer_decode(encoded.tokens), to_encode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "escoNpzllduf",
        "outputId": "95b4cd49-7b2c-428e-f4d4-f78b85a4df0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('i have been with petronas for years i feel that petronas has performed well and made a huge profit',\n",
              " 'i have been with petronas for years i feel that petronas has performed well and made a huge profit')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save(\"tokenizer.json\")"
      ],
      "metadata": {
        "id": "hcQtTVpnj50n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences = [tokenizer.encode(sentence).tokens for sentence in combined_sentences]\n",
        "tokenized_sentences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjAi8ajgkBaV",
        "outputId": "0785a7c5-9f03-410e-f1e3-e8895634b368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['okay', 'youre', 'gonna', 'need', 'to', 'learn', 'how', 'to', 'lie']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def un(d: list[list]) -> dict:\n",
        "  un = {}\n",
        "  for sen in d:\n",
        "    for t in sen:\n",
        "      if t not in un: un[t] = 0\n",
        "      un[t] += 1\n",
        "  return un"
      ],
      "metadata": {
        "id": "o9B4801EtUBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(un(tokenized_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8OwWbpYtpAC",
        "outputId": "01d60888-dc6b-4665-8e6d-920113b54b58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7056"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec training"
      ],
      "metadata": {
        "id": "yxt3wzDpjltW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "cores = multiprocessing.cpu_count()\n",
        "cores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBujyUyPkA4S",
        "outputId": "3557a628-8c0e-4128-fe24-118539c24dc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train stuff"
      ],
      "metadata": {
        "id": "ZfMlWhwjr45o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer.from_file(\"tokenizer.json\")\n",
        "tokenizer.get_vocab_size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN3eOVOd2fiN",
        "outputId": "6bdf0591-a204-4485-bbe1-64f951f57f08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7200"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "model = Word2Vec(min_count=1,\n",
        "                 window=10,\n",
        "                 vector_size=EMBEDDING_DIM,\n",
        "                 sample=6e-5,\n",
        "                 alpha=0.006,\n",
        "                 min_alpha=0.0007,\n",
        "                 negative=20,\n",
        "                 workers=cores\n",
        ")"
      ],
      "metadata": {
        "id": "59RXP2GMjhkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ts = []\n",
        "for s in tokenized_sentences: ts.append(['[PAD]'] + s + ['[EOF]'])\n",
        "ts.append(list(t for t in tokenizer.get_vocab().keys()))\n",
        "ts.append([\"[PAD]\", \"[UNK]\", \"[EOS]\", \"[EOF]\", \"[MASK]\"])\n",
        "model.build_vocab(ts)\n",
        "len(un(ts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y73T6nZ3pxqR",
        "outputId": "7f259de5-7eb8-4a52-a1d5-27570f64a911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7200"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ts[-4][:4], ts[-4][-4:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSiVHMS9zJDi",
        "outputId": "4dd019ac-11f5-4898-ef41-d828ccfe63ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['[PAD]', 'i', 'or', 'any', 'of'], ['the', 'teacher', 'arrived', '[EOF]'])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(ts, total_examples=model.corpus_count, epochs=40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JID45aUp-oK",
        "outputId": "a821dbfe-0202-43b2-dc04-c38509e01875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50531218, 131786440)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(model.wv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhTzjG8ysles",
        "outputId": "b99cce85-7d60-433b-d29b-28514b7a4fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7200"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('word2vec.model')"
      ],
      "metadata": {
        "id": "hyQj-SMjrcFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load stuff"
      ],
      "metadata": {
        "id": "2-TESGWsr8x3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "model = Word2Vec.load('word2vec.model')\n",
        "model.layer1_size, len(model.wv)"
      ],
      "metadata": {
        "id": "vYPbnrXVrmSK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "768d2f21-dd41-4a29-8375-37507b284dd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(320, 7200)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "_7Rgrrl7sy7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(positive=['i'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiB622_vsCkv",
        "outputId": "d551daea-16b0-4ef9-c566-fab7be97190c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('honestly', 0.6766033172607422),\n",
              " ('really', 0.6195955276489258),\n",
              " ('even', 0.588657021522522),\n",
              " ('actually', 0.5778974294662476),\n",
              " ('badly', 0.571925163269043),\n",
              " ('because', 0.5498996376991272),\n",
              " ('attracted', 0.5411146879196167),\n",
              " ('but', 0.5264946818351746),\n",
              " ('shouldn', 0.5257372260093689),\n",
              " ('myself', 0.5220463871955872)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(positive=['sister', 'man'], negative=['woman'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZPQYKNds1AB",
        "outputId": "fad8b7ae-f2f0-42e9-bfd5-9f7578a3e3f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('brother', 0.8064393401145935),\n",
              " ('aunt', 0.7062578797340393),\n",
              " ('frank', 0.6991549134254456),\n",
              " ('uncle', 0.6941248178482056),\n",
              " ('##law', 0.6906384229660034),\n",
              " ('cousin', 0.6893810033798218),\n",
              " ('fathers', 0.6883201599121094),\n",
              " ('nick', 0.6772075891494751),\n",
              " ('father', 0.6747114658355713),\n",
              " ('doroth', 0.6739047765731812)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v = model"
      ],
      "metadata": {
        "id": "HitTohVYknjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main dataset configuration"
      ],
      "metadata": {
        "id": "FHtBQGtetSPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def encode(token: str, w2v_model=w2v) -> torch.Tensor:\n",
        "  return torch.tensor(w2v_model.wv[token])\n",
        "\n",
        "def decode(emb: torch.Tensor, w2v_model=w2v) -> str:\n",
        "  return w2v.wv.similar_by_vector(emb.detach().numpy(), topn=1)[0][0]\n",
        "\n",
        "decode(encode('[EOF]'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "f-xxmpG6B_KC",
        "outputId": "af546e8e-3334-4f86-b063-3fddd530bfa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[EOF]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Token generation"
      ],
      "metadata": {
        "id": "VE6BpprcIKIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from collections import deque\n",
        "\n",
        "def TokenGen(data: list, w2v_model, window_size=4, shuffle=True):\n",
        "  # data is tokenized_sentences\n",
        "  # returns cat(x1, x2, ..., xn), y\n",
        "\n",
        "  if shuffle: random.shuffle(data)\n",
        "  for sentence in data:\n",
        "    window = deque([])\n",
        "    for token in sentence:\n",
        "      if token not in w2v_model.wv:\n",
        "        token = '[UNK]'\n",
        "      vec = torch.tensor(w2v_model.wv[token])\n",
        "      if len(window) == window_size:\n",
        "        yield torch.concat(list(window)), vec\n",
        "        window.append(vec)\n",
        "        window.popleft()\n",
        "        continue\n",
        "      window.append(vec)\n",
        "\n",
        "gen = TokenGen(tokenized_sentences, w2v, 2)\n",
        "for i, (w, y) in enumerate(gen):\n",
        "  print(decode(w[-EMBEDDING_DIM:]), decode(y))\n",
        "  if i > 10: break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFlm16Y7nqeT",
        "outputId": "e9e4b297-ca01-4a7d-c759-94214c92bc11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "take any\n",
            "any gu\n",
            "gu ##ff\n",
            "##ff from\n",
            "from those\n",
            "those sw\n",
            "sw ##ine\n",
            "##ine remember\n",
            "remember if\n",
            "if you\n",
            "you have\n",
            "have any\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnts = un(tokenized_sentences)\n",
        "cnts_s = sorted(cnts, key=cnts.get, reverse=True)\n",
        "{k: cnts[k] for k in cnts_s[:10]}, {k: cnts[k] for k in cnts_s[-10:]}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdLL42gX71nh",
        "outputId": "de62c1d3-c975-425a-f49d-1436b77b88a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'i': 194159,\n",
              "  'the': 78657,\n",
              "  'to': 78170,\n",
              "  'feel': 74684,\n",
              "  'and': 74316,\n",
              "  'a': 57894,\n",
              "  'of': 42568,\n",
              "  'that': 41302,\n",
              "  'you': 37078,\n",
              "  'feeling': 34175},\n",
              " {'##swald': 1,\n",
              "  'beha': 1,\n",
              "  'ener': 1,\n",
              "  '##lend': 1,\n",
              "  '##xious': 1,\n",
              "  'scen': 1,\n",
              "  'lear': 1,\n",
              "  'experi': 1,\n",
              "  '##host': 1,\n",
              "  '##arent': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch generator"
      ],
      "metadata": {
        "id": "oVpfAGLOIFgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def BatchGenerator(data: list, w2v_model, batch_size=16, window_size=4, shuffle=True):\n",
        "  tgen = TokenGen(data, w2v_model, window_size, shuffle)\n",
        "  batch_x, batch_y = [], []\n",
        "  for x, y in tgen:\n",
        "    batch_x.append(x)\n",
        "    batch_y.append(y)\n",
        "    if len(batch_x) == batch_size:\n",
        "      yield torch.stack(batch_x), torch.stack(batch_y) # (16, 4, 320), (16, 320)\n",
        "      batch_x, batch_y = [], []\n",
        "  if batch_x and batch_y:\n",
        "    yield torch.stack(batch_x), torch.stack(batch_y)\n",
        "\n",
        "gen = BatchGenerator(tokenized_sentences, w2v, 16, 24)\n",
        "\n",
        "for i, (x, y) in enumerate(gen):\n",
        "  print(x.shape, y.shape)\n",
        "  if i > 4: break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jasmdEw3IOrs",
        "outputId": "d3a8be98-b140-4719-f56e-6ea301c000ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 7680]) torch.Size([16, 320])\n",
            "torch.Size([16, 7680]) torch.Size([16, 320])\n",
            "torch.Size([16, 7680]) torch.Size([16, 320])\n",
            "torch.Size([16, 7680]) torch.Size([16, 320])\n",
            "torch.Size([16, 7680]) torch.Size([16, 320])\n",
            "torch.Size([16, 7680]) torch.Size([16, 320])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "iVoibIRgOqxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "28jfDkRTR_dk",
        "outputId": "6e03af2f-a304-44b3-9e4c-31fa2838e661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.1+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.9 torchmetrics-1.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A bit data before"
      ],
      "metadata": {
        "id": "5I_gk4zPsE58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = []\n",
        "for s in tokenized_sentences:\n",
        "  tokens.append(s + ['[EOF]'])\n",
        "tokens[-1][:4], tokens[-1][-4:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ9qWt0ne20o",
        "outputId": "46a90de9-c25c-430e-a509-24a060780327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['i', 'feel', 'a', 'world'], ['would', 'be', 'fantastic', '[EOF]'])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def total(snts: list[list[str]]) -> int:\n",
        "  total = 0\n",
        "  for s in snts:\n",
        "    for t in s:\n",
        "      total += 1\n",
        "  return total\n",
        "\n",
        "total(tokenized_sentences), total(tokens), total(tokens) / total(tokenized_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bNlIzjcghU2",
        "outputId": "819be990-32ae-4479-ab5f-9856b02e2fa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2983282, 3135369, 1.0509797598751978)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_per = 0.9\n",
        "\n",
        "l = len(tokens)\n",
        "random.shuffle(tokens)\n",
        "train_sentences = tokens[:int(l * train_per)]\n",
        "val_sentences = tokens[int(l * train_per):]\n",
        "len(train_sentences), len(val_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YFMQD__sKUX",
        "outputId": "93d918d1-0d53-42ec-a119-2134e8cd5fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(136878, 15209)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model it self"
      ],
      "metadata": {
        "id": "W7yrZznWsCu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCv_m76YiqxO",
        "outputId": "fb6a7176-830b-4ccf-9ee9-a7b815d71571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torchmetrics import MeanSquaredError, R2Score"
      ],
      "metadata": {
        "id": "hred1YXaV0dI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, pf_dim, dropout, device):\n",
        "        super().__init__()\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = nn.MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = nn.PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "\n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        #src = [batch size, src len, hid dim]\n",
        "\n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "\n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        #src = [batch size, src len, hid dim]\n",
        "\n",
        "        return src"
      ],
      "metadata": {
        "id": "LneRw8RcVxwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device, max_length = 100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList([nn.EncoderLayer(hid_dim, n_heads, pf_dim, dropout, device)\n",
        "                                     for _ in range(n_layers)])\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "\n",
        "        #pos = [batch size, src len]\n",
        "\n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "\n",
        "        #src = [batch size, src len, hid dim]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "\n",
        "        #src = [batch size, src len, hid dim]\n",
        "\n",
        "        return src"
      ],
      "metadata": {
        "id": "fsQcstMDOmz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wnd_len = 24\n",
        "hidden_size = 4096\n",
        "hidden_num = 8\n",
        "epochs = 20\n",
        "\n",
        "model = SimpleModel(EMBEDDING_DIM, wnd_len, hidden_size, hidden_num)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
        "criterion = MeanSquaredError().to(device)\n",
        "r2_metric = R2Score().to(device)"
      ],
      "metadata": {
        "id": "qmdYntaIRNRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "best_model = model\n",
        "best_score = -1e+6\n",
        "\n",
        "for e in range(epochs):\n",
        "  model.train()\n",
        "  train = BatchGenerator(train_sentences, w2v, batch_size=256, window_size=wnd_len)\n",
        "  validation = BatchGenerator(val_sentences, w2v, batch_size=256, window_size=wnd_len)\n",
        "  stime = time.time()\n",
        "\n",
        "  total_loss = 0\n",
        "  total_r2 = 0\n",
        "  total_samples = 0\n",
        "\n",
        "  for i, (X, target) in enumerate(train):\n",
        "    X = X.to(device)\n",
        "    target = target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    y = model(X)\n",
        "    loss = criterion(y, target)\n",
        "    r2 = r2_metric(y, target)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item() * X.shape[0]\n",
        "    total_r2 += r2.item() * X.shape[0]\n",
        "    total_samples += X.shape[0]\n",
        "\n",
        "    if i % 1e+2 == 0:\n",
        "      ctime = time.time()\n",
        "      print(f\"Epoch [{e + 1:2d}/{epochs}] - Batch [{i:6d}]: Loss - {(total_loss/total_samples):.5f}, Score > {(total_r2/total_samples):.5f}, Time - {(ctime-stime):.2f}s\")\n",
        "      stime = ctime\n",
        "\n",
        "      total_loss = 0\n",
        "      total_r2 = 0\n",
        "      total_samples = 0\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    total_r2 = 0\n",
        "    total_samples = 0\n",
        "    for j, (X, target) in enumerate(validation):\n",
        "      X, target = X.to(device), target.to(device)\n",
        "      y = model(X)\n",
        "      total_r2 += r2_metric(y, target).detach().item() * X.shape[0]\n",
        "      total_samples += X.shape[0]\n",
        "      # if j > 64: break\n",
        "    score = total_r2 / total_samples\n",
        "    is_update = score > best_score\n",
        "    if is_update:\n",
        "      best_model = model\n",
        "      best_score = score\n",
        "    print(f\"Epoch [{e + 1:2d}/{epochs}] validated with {score:.5f}\", \">> best model updated\" if is_update else \"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6OMWyWFxSyih",
        "outputId": "8489eeb0-e4bd-4035-eccb-2a5277cbbf82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [ 1/20] - Batch [     0]: Loss - 0.43135, Score > -1.70270, Time - 0.25s\n",
            "Epoch [ 1/20] - Batch [   100]: Loss - 0.20185, Score > -0.10784, Time - 11.71s\n",
            "Epoch [ 1/20] - Batch [   200]: Loss - 0.19578, Score > -0.05944, Time - 11.65s\n",
            "Epoch [ 1/20] - Batch [   300]: Loss - 0.19688, Score > -0.06120, Time - 12.05s\n",
            "Epoch [ 1/20] - Batch [   400]: Loss - 0.19603, Score > -0.06248, Time - 11.71s\n",
            "Epoch [ 1/20] - Batch [   500]: Loss - 0.19445, Score > -0.06233, Time - 11.74s\n",
            "Epoch [ 1/20] - Batch [   600]: Loss - 0.19550, Score > -0.06256, Time - 11.77s\n",
            "Epoch [ 1/20] - Batch [   700]: Loss - 0.19530, Score > -0.06334, Time - 11.81s\n",
            "Epoch [ 1/20] - Batch [   800]: Loss - 0.19613, Score > -0.06343, Time - 11.81s\n",
            "Epoch [ 1/20] - Batch [   900]: Loss - 0.19694, Score > -0.05971, Time - 11.73s\n",
            "Epoch [ 1/20] - Batch [  1000]: Loss - 0.19516, Score > -0.06008, Time - 11.77s\n",
            "Epoch [ 1/20] - Batch [  1100]: Loss - 0.19658, Score > -0.06059, Time - 11.80s\n",
            "Epoch [ 1/20] - Batch [  1200]: Loss - 0.19547, Score > -0.06164, Time - 11.82s\n",
            "Epoch [ 1/20] - Batch [  1300]: Loss - 0.19585, Score > -0.06222, Time - 11.83s\n",
            "Epoch [ 1/20] - Batch [  1400]: Loss - 0.19714, Score > -0.06115, Time - 11.84s\n",
            "Epoch [ 1/20] - Batch [  1500]: Loss - 0.19642, Score > -0.06147, Time - 11.84s\n",
            "Epoch [ 1/20] - Batch [  1600]: Loss - 0.19589, Score > -0.06301, Time - 11.87s\n",
            "Epoch [ 1/20] - Batch [  1700]: Loss - 0.19547, Score > -0.06192, Time - 11.89s\n",
            "Epoch [ 1/20] - Batch [  1800]: Loss - 0.19756, Score > -0.06174, Time - 11.87s\n",
            "Epoch [ 1/20] - Batch [  1900]: Loss - 0.19507, Score > -0.06119, Time - 11.91s\n",
            "Epoch [ 1/20] - Batch [  2000]: Loss - 0.19522, Score > -0.06241, Time - 11.90s\n",
            "Epoch [ 1/20] - Batch [  2100]: Loss - 0.19488, Score > -0.06298, Time - 11.91s\n",
            "Epoch [ 1/20] - Batch [  2200]: Loss - 0.19606, Score > -0.06214, Time - 11.85s\n",
            "Epoch [ 1/20] - Batch [  2300]: Loss - 0.19487, Score > -0.06174, Time - 11.90s\n",
            "Epoch [ 1/20] - Batch [  2400]: Loss - 0.19618, Score > -0.06146, Time - 11.94s\n",
            "Epoch [ 1/20] - Batch [  2500]: Loss - 0.19511, Score > -0.06101, Time - 11.96s\n",
            "Epoch [ 1/20] - Batch [  2600]: Loss - 0.19555, Score > -0.06168, Time - 11.96s\n",
            "Epoch [ 1/20] - Batch [  2700]: Loss - 0.19503, Score > -0.06116, Time - 12.01s\n",
            "Epoch [ 1/20] - Batch [  2800]: Loss - 0.19623, Score > -0.06158, Time - 11.97s\n",
            "Epoch [ 1/20] - Batch [  2900]: Loss - 0.19647, Score > -0.06103, Time - 11.98s\n",
            "Epoch [ 1/20] - Batch [  3000]: Loss - 0.19453, Score > -0.06346, Time - 11.99s\n",
            "Epoch [ 1/20] - Batch [  3100]: Loss - 0.19596, Score > -0.06191, Time - 11.89s\n",
            "Epoch [ 1/20] - Batch [  3200]: Loss - 0.19715, Score > -0.06095, Time - 11.90s\n",
            "Epoch [ 1/20] - Batch [  3300]: Loss - 0.19633, Score > -0.06229, Time - 11.90s\n",
            "Epoch [ 1/20] - Batch [  3400]: Loss - 0.19579, Score > -0.06208, Time - 11.90s\n",
            "Epoch [ 1/20] - Batch [  3500]: Loss - 0.19617, Score > -0.06234, Time - 11.91s\n",
            "Epoch [ 1/20] - Batch [  3600]: Loss - 0.19695, Score > -0.06002, Time - 11.89s\n",
            "Epoch [ 1/20] - Batch [  3700]: Loss - 0.19688, Score > -0.06243, Time - 11.90s\n",
            "Epoch [ 1/20] - Batch [  3800]: Loss - 0.19445, Score > -0.06261, Time - 11.89s\n",
            "Epoch [ 1/20] - Batch [  3900]: Loss - 0.19574, Score > -0.06073, Time - 11.90s\n",
            "Epoch [ 1/20] - Batch [  4000]: Loss - 0.19711, Score > -0.06235, Time - 11.87s\n",
            "Epoch [ 1/20] - Batch [  4100]: Loss - 0.19514, Score > -0.06214, Time - 11.84s\n",
            "Epoch [ 1/20] - Batch [  4200]: Loss - 0.19527, Score > -0.06223, Time - 11.89s\n",
            "Epoch [ 1/20] - Batch [  4300]: Loss - 0.19637, Score > -0.06105, Time - 11.85s\n",
            "Epoch [ 1/20] - Batch [  4400]: Loss - 0.19639, Score > -0.06161, Time - 11.88s\n",
            "Epoch [ 1/20] - Batch [  4500]: Loss - 0.19473, Score > -0.06302, Time - 11.88s\n",
            "Epoch [ 1/20] - Batch [  4600]: Loss - 0.19599, Score > -0.06120, Time - 11.88s\n",
            "Epoch [ 1/20] - Batch [  4700]: Loss - 0.19593, Score > -0.06140, Time - 11.92s\n",
            "Epoch [ 1/20] - Batch [  4800]: Loss - 0.19636, Score > -0.06101, Time - 11.93s\n",
            "Epoch [ 1/20] - Batch [  4900]: Loss - 0.19465, Score > -0.06190, Time - 11.95s\n",
            "Epoch [ 1/20] - Batch [  5000]: Loss - 0.19616, Score > -0.05968, Time - 11.95s\n",
            "Epoch [ 1/20] - Batch [  5100]: Loss - 0.19516, Score > -0.06129, Time - 11.94s\n",
            "Epoch [ 1/20] - Batch [  5200]: Loss - 0.19567, Score > -0.06175, Time - 11.95s\n",
            "Epoch [ 1/20] - Batch [  5300]: Loss - 0.19616, Score > -0.06221, Time - 11.87s\n",
            "Epoch [ 1/20] - Batch [  5400]: Loss - 0.19586, Score > -0.06277, Time - 11.86s\n",
            "Epoch [ 1/20] - Batch [  5500]: Loss - 0.19474, Score > -0.06266, Time - 11.87s\n",
            "Epoch [ 1/20] - Batch [  5600]: Loss - 0.19690, Score > -0.06169, Time - 11.87s\n",
            "Epoch [ 1/20] - Batch [  5700]: Loss - 0.19538, Score > -0.06183, Time - 11.92s\n",
            "Epoch [ 1/20] - Batch [  5800]: Loss - 0.19646, Score > -0.06197, Time - 11.89s\n",
            "Epoch [ 1/20] - Batch [  5900]: Loss - 0.19589, Score > -0.06174, Time - 11.92s\n",
            "Epoch [ 1/20] - Batch [  6000]: Loss - 0.19611, Score > -0.06194, Time - 11.93s\n",
            "Epoch [ 1/20] - Batch [  6100]: Loss - 0.19496, Score > -0.06222, Time - 11.90s\n",
            "Epoch [ 1/20] - Batch [  6200]: Loss - 0.19690, Score > -0.06064, Time - 11.96s\n",
            "Epoch [ 1/20] - Batch [  6300]: Loss - 0.19552, Score > -0.06235, Time - 11.89s\n",
            "Epoch [ 1/20] - Batch [  6400]: Loss - 0.19655, Score > -0.06129, Time - 11.91s\n",
            "Epoch [ 1/20] - Batch [  6500]: Loss - 0.19451, Score > -0.06129, Time - 11.93s\n",
            "Epoch [ 1/20] - Batch [  6600]: Loss - 0.19625, Score > -0.06214, Time - 11.96s\n",
            "Epoch [ 1/20] - Batch [  6700]: Loss - 0.19632, Score > -0.06165, Time - 11.99s\n",
            "Epoch [ 1/20] - Batch [  6800]: Loss - 0.19736, Score > -0.06247, Time - 11.95s\n",
            "Epoch [ 1/20] - Batch [  6900]: Loss - 0.19536, Score > -0.06261, Time - 11.88s\n",
            "Epoch [ 1/20] - Batch [  7000]: Loss - 0.19533, Score > -0.06152, Time - 11.87s\n",
            "Epoch [ 1/20] - Batch [  7100]: Loss - 0.19692, Score > -0.06130, Time - 11.88s\n",
            "Epoch [ 1/20] - Batch [  7200]: Loss - 0.19610, Score > -0.06056, Time - 11.93s\n",
            "Epoch [ 1/20] - Batch [  7300]: Loss - 0.19521, Score > -0.06185, Time - 11.90s\n",
            "Epoch [ 1/20] - Batch [  7400]: Loss - 0.19621, Score > -0.06366, Time - 11.87s\n",
            "Epoch [ 1/20] - Batch [  7500]: Loss - 0.19543, Score > -0.06001, Time - 11.89s\n",
            "Epoch [ 1/20] - Batch [  7600]: Loss - 0.19609, Score > -0.06279, Time - 11.92s\n",
            "Epoch [ 1/20] - Batch [  7700]: Loss - 0.19569, Score > -0.06199, Time - 11.93s\n",
            "Epoch [ 1/20] - Batch [  7800]: Loss - 0.19542, Score > -0.06106, Time - 11.88s\n",
            "Epoch [ 1/20] - Batch [  7900]: Loss - 0.19588, Score > -0.06070, Time - 11.87s\n",
            "Epoch [ 1/20] - Batch [  8000]: Loss - 0.19570, Score > -0.06163, Time - 11.89s\n",
            "Epoch [ 1/20] - Batch [  8100]: Loss - 0.19635, Score > -0.06137, Time - 11.85s\n",
            "Epoch [ 1/20] - Batch [  8200]: Loss - 0.19561, Score > -0.06108, Time - 11.91s\n",
            "Epoch [ 1/20] - Batch [  8300]: Loss - 0.19528, Score > -0.06249, Time - 11.87s\n",
            "Epoch [ 1/20] - Batch [  8400]: Loss - 0.19572, Score > -0.06018, Time - 11.86s\n",
            "Epoch [ 1/20] - Batch [  8500]: Loss - 0.19497, Score > -0.06277, Time - 11.89s\n",
            "Epoch [ 1/20] - Batch [  8600]: Loss - 0.19648, Score > -0.06140, Time - 11.85s\n",
            "Epoch [ 1/20] - Batch [  8700]: Loss - 0.19518, Score > -0.06177, Time - 11.90s\n",
            "Epoch [ 1/20] - Batch [  8800]: Loss - 0.19485, Score > -0.06207, Time - 11.88s\n",
            "Epoch [ 1/20] validated with -0.06146 >> best model updated\n",
            "Epoch [ 2/20] - Batch [     0]: Loss - 0.20403, Score > -0.07418, Time - 0.29s\n",
            "Epoch [ 2/20] - Batch [   100]: Loss - 0.19468, Score > -0.06257, Time - 11.84s\n",
            "Epoch [ 2/20] - Batch [   200]: Loss - 0.19600, Score > -0.06224, Time - 11.81s\n",
            "Epoch [ 2/20] - Batch [   300]: Loss - 0.19558, Score > -0.06209, Time - 11.85s\n",
            "Epoch [ 2/20] - Batch [   400]: Loss - 0.19587, Score > -0.06177, Time - 11.89s\n",
            "Epoch [ 2/20] - Batch [   500]: Loss - 0.19758, Score > -0.05982, Time - 11.90s\n",
            "Epoch [ 2/20] - Batch [   600]: Loss - 0.19652, Score > -0.06206, Time - 11.95s\n",
            "Epoch [ 2/20] - Batch [   700]: Loss - 0.19613, Score > -0.06267, Time - 11.94s\n",
            "Epoch [ 2/20] - Batch [   800]: Loss - 0.19435, Score > -0.06264, Time - 11.92s\n",
            "Epoch [ 2/20] - Batch [   900]: Loss - 0.19688, Score > -0.06191, Time - 11.88s\n",
            "Epoch [ 2/20] - Batch [  1000]: Loss - 0.19623, Score > -0.06124, Time - 11.86s\n",
            "Epoch [ 2/20] - Batch [  1100]: Loss - 0.19630, Score > -0.06108, Time - 11.89s\n",
            "Epoch [ 2/20] - Batch [  1200]: Loss - 0.19555, Score > -0.06024, Time - 11.87s\n",
            "Epoch [ 2/20] - Batch [  1300]: Loss - 0.19519, Score > -0.06176, Time - 11.88s\n",
            "Epoch [ 2/20] - Batch [  1400]: Loss - 0.19642, Score > -0.06199, Time - 11.87s\n",
            "Epoch [ 2/20] - Batch [  1500]: Loss - 0.19734, Score > -0.06076, Time - 11.82s\n",
            "Epoch [ 2/20] - Batch [  1600]: Loss - 0.19583, Score > -0.06200, Time - 11.86s\n",
            "Epoch [ 2/20] - Batch [  1700]: Loss - 0.19578, Score > -0.06192, Time - 11.83s\n",
            "Epoch [ 2/20] - Batch [  1800]: Loss - 0.19484, Score > -0.06137, Time - 11.86s\n",
            "Epoch [ 2/20] - Batch [  1900]: Loss - 0.19591, Score > -0.06300, Time - 11.88s\n",
            "Epoch [ 2/20] - Batch [  2000]: Loss - 0.19649, Score > -0.06194, Time - 11.87s\n",
            "Epoch [ 2/20] - Batch [  2100]: Loss - 0.19590, Score > -0.06164, Time - 11.93s\n",
            "Epoch [ 2/20] - Batch [  2200]: Loss - 0.19664, Score > -0.06140, Time - 11.92s\n",
            "Epoch [ 2/20] - Batch [  2300]: Loss - 0.19651, Score > -0.06117, Time - 11.97s\n",
            "Epoch [ 2/20] - Batch [  2400]: Loss - 0.19608, Score > -0.06356, Time - 11.99s\n",
            "Epoch [ 2/20] - Batch [  2500]: Loss - 0.19622, Score > -0.06292, Time - 11.94s\n",
            "Epoch [ 2/20] - Batch [  2600]: Loss - 0.19458, Score > -0.06335, Time - 11.91s\n",
            "Epoch [ 2/20] - Batch [  2700]: Loss - 0.19602, Score > -0.06145, Time - 11.88s\n",
            "Epoch [ 2/20] - Batch [  2800]: Loss - 0.19586, Score > -0.06195, Time - 11.87s\n",
            "Epoch [ 2/20] - Batch [  2900]: Loss - 0.19624, Score > -0.05993, Time - 11.82s\n",
            "Epoch [ 2/20] - Batch [  3000]: Loss - 0.19588, Score > -0.06184, Time - 11.84s\n",
            "Epoch [ 2/20] - Batch [  3100]: Loss - 0.19483, Score > -0.06258, Time - 11.85s\n",
            "Epoch [ 2/20] - Batch [  3200]: Loss - 0.19534, Score > -0.06170, Time - 11.85s\n",
            "Epoch [ 2/20] - Batch [  3300]: Loss - 0.19420, Score > -0.06197, Time - 11.90s\n",
            "Epoch [ 2/20] - Batch [  3400]: Loss - 0.19661, Score > -0.06137, Time - 11.90s\n",
            "Epoch [ 2/20] - Batch [  3500]: Loss - 0.19680, Score > -0.06170, Time - 11.87s\n",
            "Epoch [ 2/20] - Batch [  3600]: Loss - 0.19399, Score > -0.06302, Time - 11.90s\n",
            "Epoch [ 2/20] - Batch [  3700]: Loss - 0.19649, Score > -0.06154, Time - 11.89s\n",
            "Epoch [ 2/20] - Batch [  3800]: Loss - 0.19457, Score > -0.06210, Time - 11.90s\n",
            "Epoch [ 2/20] - Batch [  3900]: Loss - 0.19554, Score > -0.06313, Time - 11.88s\n",
            "Epoch [ 2/20] - Batch [  4000]: Loss - 0.19454, Score > -0.06293, Time - 11.86s\n",
            "Epoch [ 2/20] - Batch [  4100]: Loss - 0.19481, Score > -0.06237, Time - 11.94s\n",
            "Epoch [ 2/20] - Batch [  4200]: Loss - 0.19618, Score > -0.06257, Time - 11.99s\n",
            "Epoch [ 2/20] - Batch [  4300]: Loss - 0.19565, Score > -0.06266, Time - 11.91s\n",
            "Epoch [ 2/20] - Batch [  4400]: Loss - 0.19559, Score > -0.06232, Time - 11.87s\n",
            "Epoch [ 2/20] - Batch [  4500]: Loss - 0.19619, Score > -0.06094, Time - 11.85s\n",
            "Epoch [ 2/20] - Batch [  4600]: Loss - 0.19585, Score > -0.06349, Time - 11.90s\n",
            "Epoch [ 2/20] - Batch [  4700]: Loss - 0.19442, Score > -0.06082, Time - 11.95s\n",
            "Epoch [ 2/20] - Batch [  4800]: Loss - 0.19661, Score > -0.06117, Time - 11.93s\n",
            "Epoch [ 2/20] - Batch [  4900]: Loss - 0.19694, Score > -0.06128, Time - 11.94s\n",
            "Epoch [ 2/20] - Batch [  5000]: Loss - 0.19631, Score > -0.06119, Time - 11.94s\n",
            "Epoch [ 2/20] - Batch [  5100]: Loss - 0.19487, Score > -0.06182, Time - 11.93s\n",
            "Epoch [ 2/20] - Batch [  5200]: Loss - 0.19547, Score > -0.06039, Time - 11.87s\n",
            "Epoch [ 2/20] - Batch [  5300]: Loss - 0.19538, Score > -0.06302, Time - 11.90s\n",
            "Epoch [ 2/20] - Batch [  5400]: Loss - 0.19676, Score > -0.06086, Time - 11.95s\n",
            "Epoch [ 2/20] - Batch [  5500]: Loss - 0.19529, Score > -0.06051, Time - 11.94s\n",
            "Epoch [ 2/20] - Batch [  5600]: Loss - 0.19457, Score > -0.06232, Time - 11.97s\n",
            "Epoch [ 2/20] - Batch [  5700]: Loss - 0.19469, Score > -0.06141, Time - 11.91s\n",
            "Epoch [ 2/20] - Batch [  5800]: Loss - 0.19554, Score > -0.06087, Time - 11.92s\n",
            "Epoch [ 2/20] - Batch [  5900]: Loss - 0.19547, Score > -0.06013, Time - 11.91s\n",
            "Epoch [ 2/20] - Batch [  6000]: Loss - 0.19592, Score > -0.06114, Time - 11.87s\n",
            "Epoch [ 2/20] - Batch [  6100]: Loss - 0.19628, Score > -0.06190, Time - 11.86s\n",
            "Epoch [ 2/20] - Batch [  6200]: Loss - 0.19440, Score > -0.06141, Time - 11.84s\n",
            "Epoch [ 2/20] - Batch [  6300]: Loss - 0.19609, Score > -0.06209, Time - 11.89s\n",
            "Epoch [ 2/20] - Batch [  6400]: Loss - 0.19468, Score > -0.06133, Time - 11.90s\n",
            "Epoch [ 2/20] - Batch [  6500]: Loss - 0.19591, Score > -0.06227, Time - 11.89s\n",
            "Epoch [ 2/20] - Batch [  6600]: Loss - 0.19648, Score > -0.06143, Time - 11.89s\n",
            "Epoch [ 2/20] - Batch [  6700]: Loss - 0.19626, Score > -0.06166, Time - 11.91s\n",
            "Epoch [ 2/20] - Batch [  6800]: Loss - 0.19709, Score > -0.07068, Time - 11.86s\n",
            "Epoch [ 2/20] - Batch [  6900]: Loss - 0.19752, Score > -0.06922, Time - 11.89s\n",
            "Epoch [ 2/20] - Batch [  7000]: Loss - 0.19739, Score > -0.06879, Time - 11.92s\n",
            "Epoch [ 2/20] - Batch [  7100]: Loss - 0.19753, Score > -0.06824, Time - 11.90s\n",
            "Epoch [ 2/20] - Batch [  7200]: Loss - 0.19794, Score > -0.06886, Time - 11.96s\n",
            "Epoch [ 2/20] - Batch [  7300]: Loss - 0.19718, Score > -0.06932, Time - 11.93s\n",
            "Epoch [ 2/20] - Batch [  7400]: Loss - 0.19746, Score > -0.07018, Time - 11.90s\n",
            "Epoch [ 2/20] - Batch [  7500]: Loss - 0.19738, Score > -0.06974, Time - 11.94s\n",
            "Epoch [ 2/20] - Batch [  7600]: Loss - 0.19709, Score > -0.06929, Time - 11.90s\n",
            "Epoch [ 2/20] - Batch [  7700]: Loss - 0.19610, Score > -0.06986, Time - 11.92s\n",
            "Epoch [ 2/20] - Batch [  7800]: Loss - 0.19794, Score > -0.06942, Time - 11.95s\n",
            "Epoch [ 2/20] - Batch [  7900]: Loss - 0.19795, Score > -0.07005, Time - 11.91s\n",
            "Epoch [ 2/20] - Batch [  8000]: Loss - 0.19821, Score > -0.06867, Time - 11.90s\n",
            "Epoch [ 2/20] - Batch [  8100]: Loss - 0.19796, Score > -0.06991, Time - 11.94s\n",
            "Epoch [ 2/20] - Batch [  8200]: Loss - 0.19837, Score > -0.07067, Time - 11.95s\n",
            "Epoch [ 2/20] - Batch [  8300]: Loss - 0.19736, Score > -0.06825, Time - 11.92s\n",
            "Epoch [ 2/20] - Batch [  8400]: Loss - 0.19723, Score > -0.06911, Time - 11.90s\n",
            "Epoch [ 2/20] - Batch [  8500]: Loss - 0.19767, Score > -0.06990, Time - 11.91s\n",
            "Epoch [ 2/20] - Batch [  8600]: Loss - 0.19857, Score > -0.06837, Time - 11.93s\n",
            "Epoch [ 2/20] - Batch [  8700]: Loss - 0.20001, Score > -0.06812, Time - 11.92s\n",
            "Epoch [ 2/20] - Batch [  8800]: Loss - 0.19814, Score > -0.06936, Time - 11.92s\n",
            "Epoch [ 2/20] validated with -0.06910 \n",
            "Epoch [ 3/20] - Batch [     0]: Loss - 0.20542, Score > -0.06535, Time - 0.18s\n",
            "Epoch [ 3/20] - Batch [   100]: Loss - 0.19673, Score > -0.06966, Time - 11.87s\n",
            "Epoch [ 3/20] - Batch [   200]: Loss - 0.19762, Score > -0.07019, Time - 11.86s\n",
            "Epoch [ 3/20] - Batch [   300]: Loss - 0.19742, Score > -0.06824, Time - 11.86s\n",
            "Epoch [ 3/20] - Batch [   400]: Loss - 0.19799, Score > -0.06976, Time - 11.87s\n",
            "Epoch [ 3/20] - Batch [   500]: Loss - 0.19687, Score > -0.06947, Time - 11.90s\n",
            "Epoch [ 3/20] - Batch [   600]: Loss - 0.19710, Score > -0.06854, Time - 11.88s\n",
            "Epoch [ 3/20] - Batch [   700]: Loss - 0.19748, Score > -0.06928, Time - 11.86s\n",
            "Epoch [ 3/20] - Batch [   800]: Loss - 0.19723, Score > -0.07017, Time - 11.86s\n",
            "Epoch [ 3/20] - Batch [   900]: Loss - 0.19822, Score > -0.06823, Time - 11.83s\n",
            "Epoch [ 3/20] - Batch [  1000]: Loss - 0.19712, Score > -0.06917, Time - 11.87s\n",
            "Epoch [ 3/20] - Batch [  1100]: Loss - 0.19667, Score > -0.06855, Time - 11.90s\n",
            "Epoch [ 3/20] - Batch [  1200]: Loss - 0.19637, Score > -0.06986, Time - 11.91s\n",
            "Epoch [ 3/20] - Batch [  1300]: Loss - 0.19644, Score > -0.06993, Time - 11.93s\n",
            "Epoch [ 3/20] - Batch [  1400]: Loss - 0.19796, Score > -0.06819, Time - 11.89s\n",
            "Epoch [ 3/20] - Batch [  1500]: Loss - 0.19769, Score > -0.06876, Time - 11.89s\n",
            "Epoch [ 3/20] - Batch [  1600]: Loss - 0.19745, Score > -0.06960, Time - 11.85s\n",
            "Epoch [ 3/20] - Batch [  1700]: Loss - 0.19768, Score > -0.06858, Time - 11.85s\n",
            "Epoch [ 3/20] - Batch [  1800]: Loss - 0.19891, Score > -0.06867, Time - 11.90s\n",
            "Epoch [ 3/20] - Batch [  1900]: Loss - 0.19537, Score > -0.07146, Time - 11.91s\n",
            "Epoch [ 3/20] - Batch [  2000]: Loss - 0.19649, Score > -0.06895, Time - 11.87s\n",
            "Epoch [ 3/20] - Batch [  2100]: Loss - 0.19767, Score > -0.06905, Time - 11.85s\n",
            "Epoch [ 3/20] - Batch [  2200]: Loss - 0.19707, Score > -0.07005, Time - 11.84s\n",
            "Epoch [ 3/20] - Batch [  2300]: Loss - 0.19720, Score > -0.06955, Time - 11.87s\n",
            "Epoch [ 3/20] - Batch [  2400]: Loss - 0.19684, Score > -0.07006, Time - 11.88s\n",
            "Epoch [ 3/20] - Batch [  2500]: Loss - 0.19683, Score > -0.06968, Time - 11.87s\n",
            "Epoch [ 3/20] - Batch [  2600]: Loss - 0.19648, Score > -0.06943, Time - 11.89s\n",
            "Epoch [ 3/20] - Batch [  2700]: Loss - 0.19888, Score > -0.06952, Time - 11.90s\n",
            "Epoch [ 3/20] - Batch [  2800]: Loss - 0.19752, Score > -0.06932, Time - 11.88s\n",
            "Epoch [ 3/20] - Batch [  2900]: Loss - 0.19801, Score > -0.06858, Time - 11.88s\n",
            "Epoch [ 3/20] - Batch [  3000]: Loss - 0.19785, Score > -0.06836, Time - 11.92s\n",
            "Epoch [ 3/20] - Batch [  3100]: Loss - 0.19723, Score > -0.06912, Time - 11.89s\n",
            "Epoch [ 3/20] - Batch [  3200]: Loss - 0.19894, Score > -0.06907, Time - 11.86s\n",
            "Epoch [ 3/20] - Batch [  3300]: Loss - 0.19695, Score > -0.07013, Time - 11.87s\n",
            "Epoch [ 3/20] - Batch [  3400]: Loss - 0.19736, Score > -0.06813, Time - 11.84s\n",
            "Epoch [ 3/20] - Batch [  3500]: Loss - 0.19717, Score > -0.06982, Time - 11.83s\n",
            "Epoch [ 3/20] - Batch [  3600]: Loss - 0.19928, Score > -0.06851, Time - 11.84s\n",
            "Epoch [ 3/20] - Batch [  3700]: Loss - 0.19715, Score > -0.07029, Time - 11.82s\n",
            "Epoch [ 3/20] - Batch [  3800]: Loss - 0.19808, Score > -0.06952, Time - 11.85s\n",
            "Epoch [ 3/20] - Batch [  3900]: Loss - 0.19717, Score > -0.06858, Time - 11.88s\n",
            "Epoch [ 3/20] - Batch [  4000]: Loss - 0.19718, Score > -0.06828, Time - 11.88s\n",
            "Epoch [ 3/20] - Batch [  4100]: Loss - 0.19743, Score > -0.06906, Time - 11.86s\n",
            "Epoch [ 3/20] - Batch [  4200]: Loss - 0.19801, Score > -0.06892, Time - 11.86s\n",
            "Epoch [ 3/20] - Batch [  4300]: Loss - 0.19742, Score > -0.07015, Time - 11.86s\n",
            "Epoch [ 3/20] - Batch [  4400]: Loss - 0.19742, Score > -0.06853, Time - 11.91s\n",
            "Epoch [ 3/20] - Batch [  4500]: Loss - 0.19761, Score > -0.06878, Time - 11.89s\n",
            "Epoch [ 3/20] - Batch [  4600]: Loss - 0.19722, Score > -0.06831, Time - 12.00s\n",
            "Epoch [ 3/20] - Batch [  4700]: Loss - 0.19726, Score > -0.07069, Time - 11.91s\n",
            "Epoch [ 3/20] - Batch [  4800]: Loss - 0.19707, Score > -0.06866, Time - 11.88s\n",
            "Epoch [ 3/20] - Batch [  4900]: Loss - 0.19722, Score > -0.06991, Time - 11.91s\n",
            "Epoch [ 3/20] - Batch [  5000]: Loss - 0.19884, Score > -0.06811, Time - 11.87s\n",
            "Epoch [ 3/20] - Batch [  5100]: Loss - 0.19726, Score > -0.07066, Time - 11.86s\n",
            "Epoch [ 3/20] - Batch [  5200]: Loss - 0.19758, Score > -0.06853, Time - 11.89s\n",
            "Epoch [ 3/20] - Batch [  5300]: Loss - 0.19698, Score > -0.06839, Time - 11.89s\n",
            "Epoch [ 3/20] - Batch [  5400]: Loss - 0.19685, Score > -0.06980, Time - 11.87s\n",
            "Epoch [ 3/20] - Batch [  5500]: Loss - 0.19716, Score > -0.06941, Time - 11.89s\n",
            "Epoch [ 3/20] - Batch [  5600]: Loss - 0.19671, Score > -0.06992, Time - 11.91s\n",
            "Epoch [ 3/20] - Batch [  5700]: Loss - 0.19801, Score > -0.06784, Time - 11.85s\n",
            "Epoch [ 3/20] - Batch [  5800]: Loss - 0.19722, Score > -0.06973, Time - 11.86s\n",
            "Epoch [ 3/20] - Batch [  5900]: Loss - 0.19818, Score > -0.06905, Time - 11.86s\n",
            "Epoch [ 3/20] - Batch [  6000]: Loss - 0.19831, Score > -0.06970, Time - 11.87s\n",
            "Epoch [ 3/20] - Batch [  6100]: Loss - 0.19648, Score > -0.06832, Time - 11.94s\n",
            "Epoch [ 3/20] - Batch [  6200]: Loss - 0.19583, Score > -0.07081, Time - 11.93s\n",
            "Epoch [ 3/20] - Batch [  6300]: Loss - 0.19757, Score > -0.06987, Time - 11.92s\n",
            "Epoch [ 3/20] - Batch [  6400]: Loss - 0.19879, Score > -0.06842, Time - 11.94s\n",
            "Epoch [ 3/20] - Batch [  6500]: Loss - 0.19701, Score > -0.07041, Time - 11.86s\n",
            "Epoch [ 3/20] - Batch [  6600]: Loss - 0.19898, Score > -0.07005, Time - 11.85s\n",
            "Epoch [ 3/20] - Batch [  6700]: Loss - 0.19860, Score > -0.06844, Time - 11.81s\n",
            "Epoch [ 3/20] - Batch [  6800]: Loss - 0.19801, Score > -0.06911, Time - 11.86s\n",
            "Epoch [ 3/20] - Batch [  6900]: Loss - 0.19874, Score > -0.06770, Time - 11.88s\n",
            "Epoch [ 3/20] - Batch [  7000]: Loss - 0.19650, Score > -0.07094, Time - 11.94s\n",
            "Epoch [ 3/20] - Batch [  7100]: Loss - 0.19646, Score > -0.06860, Time - 11.92s\n",
            "Epoch [ 3/20] - Batch [  7200]: Loss - 0.19793, Score > -0.06981, Time - 11.90s\n",
            "Epoch [ 3/20] - Batch [  7300]: Loss - 0.19722, Score > -0.06817, Time - 11.95s\n",
            "Epoch [ 3/20] - Batch [  7400]: Loss - 0.19832, Score > -0.06940, Time - 11.89s\n",
            "Epoch [ 3/20] - Batch [  7500]: Loss - 0.19750, Score > -0.06892, Time - 11.88s\n",
            "Epoch [ 3/20] - Batch [  7600]: Loss - 0.19673, Score > -0.06843, Time - 11.98s\n",
            "Epoch [ 3/20] - Batch [  7700]: Loss - 0.19715, Score > -0.06955, Time - 11.90s\n",
            "Epoch [ 3/20] - Batch [  7800]: Loss - 0.19709, Score > -0.07031, Time - 11.90s\n",
            "Epoch [ 3/20] - Batch [  7900]: Loss - 0.19817, Score > -0.06879, Time - 11.94s\n",
            "Epoch [ 3/20] - Batch [  8000]: Loss - 0.19658, Score > -0.07011, Time - 11.85s\n",
            "Epoch [ 3/20] - Batch [  8100]: Loss - 0.19709, Score > -0.06968, Time - 11.86s\n",
            "Epoch [ 3/20] - Batch [  8200]: Loss - 0.19813, Score > -0.06826, Time - 11.88s\n",
            "Epoch [ 3/20] - Batch [  8300]: Loss - 0.19801, Score > -0.07029, Time - 11.89s\n",
            "Epoch [ 3/20] - Batch [  8400]: Loss - 0.19690, Score > -0.07142, Time - 11.86s\n",
            "Epoch [ 3/20] - Batch [  8500]: Loss - 0.19859, Score > -0.06954, Time - 11.87s\n",
            "Epoch [ 3/20] - Batch [  8600]: Loss - 0.19752, Score > -0.07006, Time - 11.92s\n",
            "Epoch [ 3/20] - Batch [  8700]: Loss - 0.19705, Score > -0.07022, Time - 11.91s\n",
            "Epoch [ 3/20] - Batch [  8800]: Loss - 0.19696, Score > -0.06957, Time - 11.90s\n",
            "Epoch [ 3/20] validated with -0.06905 \n",
            "Epoch [ 4/20] - Batch [     0]: Loss - 0.19719, Score > -0.07012, Time - 0.25s\n",
            "Epoch [ 4/20] - Batch [   100]: Loss - 0.19621, Score > -0.06852, Time - 11.83s\n",
            "Epoch [ 4/20] - Batch [   200]: Loss - 0.19716, Score > -0.06995, Time - 11.91s\n",
            "Epoch [ 4/20] - Batch [   300]: Loss - 0.19788, Score > -0.07003, Time - 11.92s\n",
            "Epoch [ 4/20] - Batch [   400]: Loss - 0.19820, Score > -0.06781, Time - 11.88s\n",
            "Epoch [ 4/20] - Batch [   500]: Loss - 0.19722, Score > -0.06895, Time - 11.84s\n",
            "Epoch [ 4/20] - Batch [   600]: Loss - 0.19695, Score > -0.07010, Time - 11.84s\n",
            "Epoch [ 4/20] - Batch [   700]: Loss - 0.19823, Score > -0.06878, Time - 11.88s\n",
            "Epoch [ 4/20] - Batch [   800]: Loss - 0.19791, Score > -0.06850, Time - 11.89s\n",
            "Epoch [ 4/20] - Batch [   900]: Loss - 0.19807, Score > -0.06691, Time - 11.89s\n",
            "Epoch [ 4/20] - Batch [  1000]: Loss - 0.19565, Score > -0.07084, Time - 11.88s\n",
            "Epoch [ 4/20] - Batch [  1100]: Loss - 0.19708, Score > -0.06925, Time - 11.85s\n",
            "Epoch [ 4/20] - Batch [  1200]: Loss - 0.19763, Score > -0.06882, Time - 11.89s\n",
            "Epoch [ 4/20] - Batch [  1300]: Loss - 0.19770, Score > -0.06920, Time - 11.90s\n",
            "Epoch [ 4/20] - Batch [  1400]: Loss - 0.19721, Score > -0.06954, Time - 11.87s\n",
            "Epoch [ 4/20] - Batch [  1500]: Loss - 0.20002, Score > -0.06842, Time - 11.88s\n",
            "Epoch [ 4/20] - Batch [  1600]: Loss - 0.19699, Score > -0.06941, Time - 11.85s\n",
            "Epoch [ 4/20] - Batch [  1700]: Loss - 0.19720, Score > -0.06804, Time - 11.89s\n",
            "Epoch [ 4/20] - Batch [  1800]: Loss - 0.19550, Score > -0.06976, Time - 11.93s\n",
            "Epoch [ 4/20] - Batch [  1900]: Loss - 0.19721, Score > -0.06977, Time - 11.91s\n",
            "Epoch [ 4/20] - Batch [  2000]: Loss - 0.19780, Score > -0.06898, Time - 11.90s\n",
            "Epoch [ 4/20] - Batch [  2100]: Loss - 0.19785, Score > -0.06950, Time - 11.88s\n",
            "Epoch [ 4/20] - Batch [  2200]: Loss - 0.19681, Score > -0.06962, Time - 11.88s\n",
            "Epoch [ 4/20] - Batch [  2300]: Loss - 0.19739, Score > -0.06778, Time - 11.88s\n",
            "Epoch [ 4/20] - Batch [  2400]: Loss - 0.19801, Score > -0.06839, Time - 11.87s\n",
            "Epoch [ 4/20] - Batch [  2500]: Loss - 0.19813, Score > -0.06850, Time - 11.90s\n",
            "Epoch [ 4/20] - Batch [  2600]: Loss - 0.19785, Score > -0.06949, Time - 11.88s\n",
            "Epoch [ 4/20] - Batch [  2700]: Loss - 0.19751, Score > -0.06868, Time - 11.87s\n",
            "Epoch [ 4/20] - Batch [  2800]: Loss - 0.19691, Score > -0.06890, Time - 11.85s\n",
            "Epoch [ 4/20] - Batch [  2900]: Loss - 0.19815, Score > -0.06884, Time - 11.84s\n",
            "Epoch [ 4/20] - Batch [  3000]: Loss - 0.19704, Score > -0.06919, Time - 11.87s\n",
            "Epoch [ 4/20] - Batch [  3100]: Loss - 0.19843, Score > -0.06967, Time - 11.88s\n",
            "Epoch [ 4/20] - Batch [  3200]: Loss - 0.19716, Score > -0.06935, Time - 11.89s\n",
            "Epoch [ 4/20] - Batch [  3300]: Loss - 0.19655, Score > -0.07033, Time - 11.91s\n",
            "Epoch [ 4/20] - Batch [  3400]: Loss - 0.19718, Score > -0.06879, Time - 11.88s\n",
            "Epoch [ 4/20] - Batch [  3500]: Loss - 0.19752, Score > -0.06984, Time - 11.93s\n",
            "Epoch [ 4/20] - Batch [  3600]: Loss - 0.19619, Score > -0.06868, Time - 11.89s\n",
            "Epoch [ 4/20] - Batch [  3700]: Loss - 0.19820, Score > -0.06708, Time - 11.89s\n",
            "Epoch [ 4/20] - Batch [  3800]: Loss - 0.19894, Score > -0.06862, Time - 11.88s\n",
            "Epoch [ 4/20] - Batch [  3900]: Loss - 0.19876, Score > -0.06845, Time - 11.82s\n",
            "Epoch [ 4/20] - Batch [  4000]: Loss - 0.19841, Score > -0.06800, Time - 11.89s\n",
            "Epoch [ 4/20] - Batch [  4100]: Loss - 0.19665, Score > -0.06965, Time - 11.86s\n",
            "Epoch [ 4/20] - Batch [  4200]: Loss - 0.19764, Score > -0.06855, Time - 11.87s\n",
            "Epoch [ 4/20] - Batch [  4300]: Loss - 0.19615, Score > -0.06798, Time - 11.89s\n",
            "Epoch [ 4/20] - Batch [  4400]: Loss - 0.19699, Score > -0.07003, Time - 11.85s\n",
            "Epoch [ 4/20] - Batch [  4500]: Loss - 0.19651, Score > -0.06914, Time - 11.86s\n",
            "Epoch [ 4/20] - Batch [  4600]: Loss - 0.19759, Score > -0.06916, Time - 11.88s\n",
            "Epoch [ 4/20] - Batch [  4700]: Loss - 0.19700, Score > -0.06927, Time - 11.87s\n",
            "Epoch [ 4/20] - Batch [  4800]: Loss - 0.19689, Score > -0.07019, Time - 11.88s\n",
            "Epoch [ 4/20] - Batch [  4900]: Loss - 0.19697, Score > -0.07020, Time - 11.89s\n",
            "Epoch [ 4/20] - Batch [  5000]: Loss - 0.19761, Score > -0.06926, Time - 11.89s\n",
            "Epoch [ 4/20] - Batch [  5100]: Loss - 0.19868, Score > -0.06927, Time - 11.92s\n",
            "Epoch [ 4/20] - Batch [  5200]: Loss - 0.19853, Score > -0.06934, Time - 11.92s\n",
            "Epoch [ 4/20] - Batch [  5300]: Loss - 0.19765, Score > -0.06956, Time - 11.92s\n",
            "Epoch [ 4/20] - Batch [  5400]: Loss - 0.19687, Score > -0.06936, Time - 11.85s\n",
            "Epoch [ 4/20] - Batch [  5500]: Loss - 0.19576, Score > -0.07073, Time - 11.86s\n",
            "Epoch [ 4/20] - Batch [  5600]: Loss - 0.19734, Score > -0.06892, Time - 11.86s\n",
            "Epoch [ 4/20] - Batch [  5700]: Loss - 0.19659, Score > -0.07018, Time - 11.85s\n",
            "Epoch [ 4/20] - Batch [  5800]: Loss - 0.19753, Score > -0.06827, Time - 11.84s\n",
            "Epoch [ 4/20] - Batch [  5900]: Loss - 0.19810, Score > -0.06964, Time - 11.86s\n",
            "Epoch [ 4/20] - Batch [  6000]: Loss - 0.19706, Score > -0.06882, Time - 11.86s\n",
            "Epoch [ 4/20] - Batch [  6100]: Loss - 0.19895, Score > -0.06957, Time - 11.86s\n",
            "Epoch [ 4/20] - Batch [  6200]: Loss - 0.19667, Score > -0.06900, Time - 11.89s\n",
            "Epoch [ 4/20] - Batch [  6300]: Loss - 0.19879, Score > -0.06854, Time - 11.91s\n",
            "Epoch [ 4/20] - Batch [  6400]: Loss - 0.19791, Score > -0.06964, Time - 11.89s\n",
            "Epoch [ 4/20] - Batch [  6500]: Loss - 0.19730, Score > -0.07024, Time - 11.92s\n",
            "Epoch [ 4/20] - Batch [  6600]: Loss - 0.19820, Score > -0.06898, Time - 11.91s\n",
            "Epoch [ 4/20] - Batch [  6700]: Loss - 0.19761, Score > -0.06868, Time - 11.91s\n",
            "Epoch [ 4/20] - Batch [  6800]: Loss - 0.19722, Score > -0.06876, Time - 11.96s\n",
            "Epoch [ 4/20] - Batch [  6900]: Loss - 0.19796, Score > -0.06886, Time - 11.92s\n",
            "Epoch [ 4/20] - Batch [  7000]: Loss - 0.19810, Score > -0.06961, Time - 11.93s\n",
            "Epoch [ 4/20] - Batch [  7100]: Loss - 0.19734, Score > -0.06916, Time - 11.88s\n",
            "Epoch [ 4/20] - Batch [  7200]: Loss - 0.19844, Score > -0.06825, Time - 11.85s\n",
            "Epoch [ 4/20] - Batch [  7300]: Loss - 0.19757, Score > -0.06943, Time - 11.86s\n",
            "Epoch [ 4/20] - Batch [  7400]: Loss - 0.19768, Score > -0.06941, Time - 11.84s\n",
            "Epoch [ 4/20] - Batch [  7500]: Loss - 0.19831, Score > -0.06835, Time - 11.86s\n",
            "Epoch [ 4/20] - Batch [  7600]: Loss - 0.19828, Score > -0.06945, Time - 11.93s\n",
            "Epoch [ 4/20] - Batch [  7700]: Loss - 0.19697, Score > -0.06938, Time - 11.91s\n",
            "Epoch [ 4/20] - Batch [  7800]: Loss - 0.19610, Score > -0.06880, Time - 11.89s\n",
            "Epoch [ 4/20] - Batch [  7900]: Loss - 0.19775, Score > -0.06899, Time - 11.90s\n",
            "Epoch [ 4/20] - Batch [  8000]: Loss - 0.19724, Score > -0.06927, Time - 11.87s\n",
            "Epoch [ 4/20] - Batch [  8100]: Loss - 0.19584, Score > -0.06991, Time - 11.91s\n",
            "Epoch [ 4/20] - Batch [  8200]: Loss - 0.19728, Score > -0.06848, Time - 11.94s\n",
            "Epoch [ 4/20] - Batch [  8300]: Loss - 0.19576, Score > -0.07089, Time - 11.98s\n",
            "Epoch [ 4/20] - Batch [  8400]: Loss - 0.19729, Score > -0.06764, Time - 11.93s\n",
            "Epoch [ 4/20] - Batch [  8500]: Loss - 0.19749, Score > -0.06962, Time - 11.89s\n",
            "Epoch [ 4/20] - Batch [  8600]: Loss - 0.19808, Score > -0.06864, Time - 11.91s\n",
            "Epoch [ 4/20] - Batch [  8700]: Loss - 0.19814, Score > -0.06963, Time - 11.88s\n",
            "Epoch [ 4/20] - Batch [  8800]: Loss - 0.19815, Score > -0.06733, Time - 11.88s\n",
            "Epoch [ 4/20] validated with -0.06912 \n",
            "Epoch [ 5/20] - Batch [     0]: Loss - 0.18430, Score > -0.07239, Time - 0.19s\n",
            "Epoch [ 5/20] - Batch [   100]: Loss - 0.19762, Score > -0.06876, Time - 11.90s\n",
            "Epoch [ 5/20] - Batch [   200]: Loss - 0.19723, Score > -0.07015, Time - 11.88s\n",
            "Epoch [ 5/20] - Batch [   300]: Loss - 0.19708, Score > -0.06891, Time - 11.88s\n",
            "Epoch [ 5/20] - Batch [   400]: Loss - 0.19762, Score > -0.06897, Time - 11.91s\n",
            "Epoch [ 5/20] - Batch [   500]: Loss - 0.19705, Score > -0.06937, Time - 11.86s\n",
            "Epoch [ 5/20] - Batch [   600]: Loss - 0.19689, Score > -0.06920, Time - 11.86s\n",
            "Epoch [ 5/20] - Batch [   700]: Loss - 0.19758, Score > -0.06931, Time - 11.90s\n",
            "Epoch [ 5/20] - Batch [   800]: Loss - 0.19912, Score > -0.06858, Time - 11.98s\n",
            "Epoch [ 5/20] - Batch [   900]: Loss - 0.19693, Score > -0.07003, Time - 11.97s\n",
            "Epoch [ 5/20] - Batch [  1000]: Loss - 0.19704, Score > -0.06866, Time - 11.95s\n",
            "Epoch [ 5/20] - Batch [  1100]: Loss - 0.19754, Score > -0.06874, Time - 11.89s\n",
            "Epoch [ 5/20] - Batch [  1200]: Loss - 0.19761, Score > -0.07074, Time - 11.89s\n",
            "Epoch [ 5/20] - Batch [  1300]: Loss - 0.19681, Score > -0.07089, Time - 11.88s\n",
            "Epoch [ 5/20] - Batch [  1400]: Loss - 0.19894, Score > -0.06789, Time - 11.88s\n",
            "Epoch [ 5/20] - Batch [  1500]: Loss - 0.19777, Score > -0.06986, Time - 11.89s\n",
            "Epoch [ 5/20] - Batch [  1600]: Loss - 0.19682, Score > -0.06939, Time - 11.86s\n",
            "Epoch [ 5/20] - Batch [  1700]: Loss - 0.19783, Score > -0.06930, Time - 11.89s\n",
            "Epoch [ 5/20] - Batch [  1800]: Loss - 0.19894, Score > -0.06833, Time - 11.87s\n",
            "Epoch [ 5/20] - Batch [  1900]: Loss - 0.19734, Score > -0.06974, Time - 11.89s\n",
            "Epoch [ 5/20] - Batch [  2000]: Loss - 0.19789, Score > -0.06829, Time - 11.87s\n",
            "Epoch [ 5/20] - Batch [  2100]: Loss - 0.19780, Score > -0.06987, Time - 11.83s\n",
            "Epoch [ 5/20] - Batch [  2200]: Loss - 0.19618, Score > -0.06908, Time - 11.87s\n",
            "Epoch [ 5/20] - Batch [  2300]: Loss - 0.19796, Score > -0.06861, Time - 11.88s\n",
            "Epoch [ 5/20] - Batch [  2400]: Loss - 0.19645, Score > -0.06879, Time - 11.95s\n",
            "Epoch [ 5/20] - Batch [  2500]: Loss - 0.19664, Score > -0.06956, Time - 11.96s\n",
            "Epoch [ 5/20] - Batch [  2600]: Loss - 0.19693, Score > -0.06949, Time - 11.93s\n",
            "Epoch [ 5/20] - Batch [  2700]: Loss - 0.19635, Score > -0.07016, Time - 11.92s\n",
            "Epoch [ 5/20] - Batch [  2800]: Loss - 0.19640, Score > -0.07025, Time - 11.93s\n",
            "Epoch [ 5/20] - Batch [  2900]: Loss - 0.19697, Score > -0.06882, Time - 11.94s\n",
            "Epoch [ 5/20] - Batch [  3000]: Loss - 0.19730, Score > -0.06945, Time - 11.90s\n",
            "Epoch [ 5/20] - Batch [  3100]: Loss - 0.19735, Score > -0.06935, Time - 11.88s\n",
            "Epoch [ 5/20] - Batch [  3200]: Loss - 0.19619, Score > -0.07009, Time - 11.89s\n",
            "Epoch [ 5/20] - Batch [  3300]: Loss - 0.19729, Score > -0.06985, Time - 11.87s\n",
            "Epoch [ 5/20] - Batch [  3400]: Loss - 0.19774, Score > -0.06999, Time - 11.87s\n",
            "Epoch [ 5/20] - Batch [  3500]: Loss - 0.19664, Score > -0.07011, Time - 11.88s\n",
            "Epoch [ 5/20] - Batch [  3600]: Loss - 0.19722, Score > -0.07090, Time - 11.88s\n",
            "Epoch [ 5/20] - Batch [  3700]: Loss - 0.19919, Score > -0.06866, Time - 11.86s\n",
            "Epoch [ 5/20] - Batch [  3800]: Loss - 0.19769, Score > -0.06919, Time - 11.85s\n",
            "Epoch [ 5/20] - Batch [  3900]: Loss - 0.19920, Score > -0.06847, Time - 11.92s\n",
            "Epoch [ 5/20] - Batch [  4000]: Loss - 0.19755, Score > -0.06841, Time - 11.94s\n",
            "Epoch [ 5/20] - Batch [  4100]: Loss - 0.19892, Score > -0.06868, Time - 11.95s\n",
            "Epoch [ 5/20] - Batch [  4200]: Loss - 0.19753, Score > -0.06935, Time - 11.92s\n",
            "Epoch [ 5/20] - Batch [  4300]: Loss - 0.19644, Score > -0.06914, Time - 11.92s\n",
            "Epoch [ 5/20] - Batch [  4400]: Loss - 0.19732, Score > -0.06844, Time - 11.89s\n",
            "Epoch [ 5/20] - Batch [  4500]: Loss - 0.19765, Score > -0.07011, Time - 11.88s\n",
            "Epoch [ 5/20] - Batch [  4600]: Loss - 0.19689, Score > -0.06806, Time - 11.86s\n",
            "Epoch [ 5/20] - Batch [  4700]: Loss - 0.19785, Score > -0.06818, Time - 11.91s\n",
            "Epoch [ 5/20] - Batch [  4800]: Loss - 0.19746, Score > -0.06951, Time - 11.89s\n",
            "Epoch [ 5/20] - Batch [  4900]: Loss - 0.19640, Score > -0.06988, Time - 11.89s\n",
            "Epoch [ 5/20] - Batch [  5000]: Loss - 0.19794, Score > -0.06808, Time - 11.88s\n",
            "Epoch [ 5/20] - Batch [  5100]: Loss - 0.19801, Score > -0.07004, Time - 11.82s\n",
            "Epoch [ 5/20] - Batch [  5200]: Loss - 0.19983, Score > -0.08102, Time - 11.86s\n",
            "Epoch [ 5/20] - Batch [  5300]: Loss - 0.19861, Score > -0.07918, Time - 11.88s\n",
            "Epoch [ 5/20] - Batch [  5400]: Loss - 0.19917, Score > -0.08093, Time - 11.90s\n",
            "Epoch [ 5/20] - Batch [  5500]: Loss - 0.19994, Score > -0.08121, Time - 11.89s\n",
            "Epoch [ 5/20] - Batch [  5600]: Loss - 0.19814, Score > -0.07948, Time - 11.96s\n",
            "Epoch [ 5/20] - Batch [  5700]: Loss - 0.19930, Score > -0.07658, Time - 11.96s\n",
            "Epoch [ 5/20] - Batch [  5800]: Loss - 0.29419, Score > -0.67803, Time - 11.97s\n",
            "Epoch [ 5/20] - Batch [  5900]: Loss - 0.91773, Score > -4.67259, Time - 11.99s\n",
            "Epoch [ 5/20] - Batch [  6000]: Loss - 0.24827, Score > -0.36654, Time - 11.93s\n",
            "Epoch [ 5/20] - Batch [  6100]: Loss - 0.24168, Score > -0.32492, Time - 11.90s\n",
            "Epoch [ 5/20] - Batch [  6200]: Loss - 0.24283, Score > -0.32865, Time - 11.95s\n",
            "Epoch [ 5/20] - Batch [  6300]: Loss - 0.33919, Score > -0.96502, Time - 11.95s\n",
            "Epoch [ 5/20] - Batch [  6400]: Loss - 1.07696, Score > -5.66571, Time - 11.95s\n",
            "Epoch [ 5/20] - Batch [  6500]: Loss - 1.03502, Score > -5.45907, Time - 11.97s\n",
            "Epoch [ 5/20] - Batch [  6600]: Loss - 1.04597, Score > -5.50991, Time - 11.92s\n",
            "Epoch [ 5/20] - Batch [  6700]: Loss - 1.05485, Score > -5.52311, Time - 11.91s\n",
            "Epoch [ 5/20] - Batch [  6800]: Loss - 1.06247, Score > -5.59780, Time - 11.92s\n",
            "Epoch [ 5/20] - Batch [  6900]: Loss - 1.16648, Score > -6.23643, Time - 11.93s\n",
            "Epoch [ 5/20] - Batch [  7000]: Loss - 1.16626, Score > -6.25542, Time - 12.00s\n",
            "Epoch [ 5/20] - Batch [  7100]: Loss - 1.16713, Score > -6.23119, Time - 11.96s\n",
            "Epoch [ 5/20] - Batch [  7200]: Loss - 1.16543, Score > -6.20176, Time - 11.94s\n",
            "Epoch [ 5/20] - Batch [  7300]: Loss - 1.16258, Score > -6.17532, Time - 11.94s\n",
            "Epoch [ 5/20] - Batch [  7400]: Loss - 1.16019, Score > -6.24286, Time - 11.94s\n",
            "Epoch [ 5/20] - Batch [  7500]: Loss - 1.06939, Score > -5.59496, Time - 11.93s\n",
            "Epoch [ 5/20] - Batch [  7600]: Loss - 1.08588, Score > -5.75905, Time - 11.93s\n",
            "Epoch [ 5/20] - Batch [  7700]: Loss - 1.04970, Score > -5.45234, Time - 11.89s\n",
            "Epoch [ 5/20] - Batch [  7800]: Loss - 1.03688, Score > -5.39806, Time - 11.91s\n",
            "Epoch [ 5/20] - Batch [  7900]: Loss - 1.04828, Score > -5.43187, Time - 11.89s\n",
            "Epoch [ 5/20] - Batch [  8000]: Loss - 1.04639, Score > -5.45592, Time - 11.92s\n",
            "Epoch [ 5/20] - Batch [  8100]: Loss - 1.05047, Score > -5.49938, Time - 11.96s\n",
            "Epoch [ 5/20] - Batch [  8200]: Loss - 1.03879, Score > -5.39052, Time - 11.99s\n",
            "Epoch [ 5/20] - Batch [  8300]: Loss - 1.04456, Score > -5.39816, Time - 11.96s\n",
            "Epoch [ 5/20] - Batch [  8400]: Loss - 1.04761, Score > -5.47849, Time - 12.00s\n",
            "Epoch [ 5/20] - Batch [  8500]: Loss - 1.03824, Score > -5.41804, Time - 12.00s\n",
            "Epoch [ 5/20] - Batch [  8600]: Loss - 1.03467, Score > -5.41605, Time - 12.02s\n",
            "Epoch [ 5/20] - Batch [  8700]: Loss - 1.04136, Score > -5.39713, Time - 11.95s\n",
            "Epoch [ 5/20] - Batch [  8800]: Loss - 1.05858, Score > -5.55213, Time - 12.02s\n",
            "Epoch [ 5/20] validated with -5.42391 \n",
            "Epoch [ 6/20] - Batch [     0]: Loss - 1.14144, Score > -5.91446, Time - 0.19s\n",
            "Epoch [ 6/20] - Batch [   100]: Loss - 1.05391, Score > -5.49687, Time - 11.99s\n",
            "Epoch [ 6/20] - Batch [   200]: Loss - 1.03426, Score > -5.39525, Time - 11.93s\n",
            "Epoch [ 6/20] - Batch [   300]: Loss - 1.04117, Score > -5.45912, Time - 11.92s\n",
            "Epoch [ 6/20] - Batch [   400]: Loss - 1.04971, Score > -5.50723, Time - 11.95s\n",
            "Epoch [ 6/20] - Batch [   500]: Loss - 1.05200, Score > -5.50739, Time - 12.02s\n",
            "Epoch [ 6/20] - Batch [   600]: Loss - 1.03862, Score > -5.43432, Time - 11.99s\n",
            "Epoch [ 6/20] - Batch [   700]: Loss - 1.04536, Score > -5.46744, Time - 12.06s\n",
            "Epoch [ 6/20] - Batch [   800]: Loss - 1.04035, Score > -5.42831, Time - 12.03s\n",
            "Epoch [ 6/20] - Batch [   900]: Loss - 1.03581, Score > -5.41391, Time - 12.04s\n",
            "Epoch [ 6/20] - Batch [  1000]: Loss - 1.05515, Score > -5.52406, Time - 12.02s\n",
            "Epoch [ 6/20] - Batch [  1100]: Loss - 1.04661, Score > -5.47742, Time - 12.02s\n",
            "Epoch [ 6/20] - Batch [  1200]: Loss - 1.04068, Score > -5.44955, Time - 12.04s\n",
            "Epoch [ 6/20] - Batch [  1300]: Loss - 1.02016, Score > -5.28443, Time - 12.01s\n",
            "Epoch [ 6/20] - Batch [  1400]: Loss - 1.04632, Score > -5.47347, Time - 12.04s\n",
            "Epoch [ 6/20] - Batch [  1500]: Loss - 1.03788, Score > -5.39322, Time - 11.97s\n",
            "Epoch [ 6/20] - Batch [  1600]: Loss - 1.05065, Score > -5.50676, Time - 12.01s\n",
            "Epoch [ 6/20] - Batch [  1700]: Loss - 1.04409, Score > -5.44052, Time - 12.02s\n",
            "Epoch [ 6/20] - Batch [  1800]: Loss - 1.05554, Score > -5.42482, Time - 12.03s\n",
            "Epoch [ 6/20] - Batch [  1900]: Loss - 1.04572, Score > -5.45350, Time - 12.01s\n",
            "Epoch [ 6/20] - Batch [  2000]: Loss - 1.03669, Score > -5.38287, Time - 12.02s\n",
            "Epoch [ 6/20] - Batch [  2100]: Loss - 1.05271, Score > -5.52732, Time - 12.03s\n",
            "Epoch [ 6/20] - Batch [  2200]: Loss - 1.04930, Score > -5.45934, Time - 11.97s\n",
            "Epoch [ 6/20] - Batch [  2300]: Loss - 0.96508, Score > -4.93349, Time - 12.02s\n",
            "Epoch [ 6/20] - Batch [  2400]: Loss - 0.93218, Score > -4.75391, Time - 12.08s\n",
            "Epoch [ 6/20] - Batch [  2500]: Loss - 0.94865, Score > -4.84211, Time - 12.08s\n",
            "Epoch [ 6/20] - Batch [  2600]: Loss - 0.93470, Score > -4.72542, Time - 12.02s\n",
            "Epoch [ 6/20] - Batch [  2700]: Loss - 0.94727, Score > -4.84618, Time - 12.01s\n",
            "Epoch [ 6/20] - Batch [  2800]: Loss - 0.93854, Score > -4.75240, Time - 12.02s\n",
            "Epoch [ 6/20] - Batch [  2900]: Loss - 0.95178, Score > -4.83005, Time - 12.04s\n",
            "Epoch [ 6/20] - Batch [  3000]: Loss - 0.93345, Score > -4.71483, Time - 12.03s\n",
            "Epoch [ 6/20] - Batch [  3100]: Loss - 0.75826, Score > -3.63325, Time - 12.02s\n",
            "Epoch [ 6/20] - Batch [  3200]: Loss - 0.22052, Score > -0.16929, Time - 11.99s\n",
            "Epoch [ 6/20] - Batch [  3300]: Loss - 0.22097, Score > -0.16944, Time - 12.00s\n",
            "Epoch [ 6/20] - Batch [  3400]: Loss - 0.22066, Score > -0.16911, Time - 11.98s\n",
            "Epoch [ 6/20] - Batch [  3500]: Loss - 0.22112, Score > -0.16950, Time - 11.97s\n",
            "Epoch [ 6/20] - Batch [  3600]: Loss - 0.22060, Score > -0.16995, Time - 11.97s\n",
            "Epoch [ 6/20] - Batch [  3700]: Loss - 0.21998, Score > -0.16729, Time - 11.90s\n",
            "Epoch [ 6/20] - Batch [  3800]: Loss - 0.22115, Score > -0.16746, Time - 11.95s\n",
            "Epoch [ 6/20] - Batch [  3900]: Loss - 0.22035, Score > -0.16835, Time - 11.94s\n",
            "Epoch [ 6/20] - Batch [  4000]: Loss - 0.22024, Score > -0.17046, Time - 11.97s\n",
            "Epoch [ 6/20] - Batch [  4100]: Loss - 0.22160, Score > -0.16976, Time - 12.01s\n",
            "Epoch [ 6/20] - Batch [  4200]: Loss - 0.22138, Score > -0.16742, Time - 12.00s\n",
            "Epoch [ 6/20] - Batch [  4300]: Loss - 0.22072, Score > -0.17097, Time - 11.96s\n",
            "Epoch [ 6/20] - Batch [  4400]: Loss - 0.22125, Score > -0.16826, Time - 12.00s\n",
            "Epoch [ 6/20] - Batch [  4500]: Loss - 0.22162, Score > -0.16785, Time - 12.00s\n",
            "Epoch [ 6/20] - Batch [  4600]: Loss - 0.22066, Score > -0.17032, Time - 12.00s\n",
            "Epoch [ 6/20] - Batch [  4700]: Loss - 0.21934, Score > -0.16720, Time - 12.02s\n",
            "Epoch [ 6/20] - Batch [  4800]: Loss - 0.22017, Score > -0.16938, Time - 12.01s\n",
            "Epoch [ 6/20] - Batch [  4900]: Loss - 0.71495, Score > -3.30525, Time - 11.98s\n",
            "Epoch [ 6/20] - Batch [  5000]: Loss - 0.88208, Score > -4.43861, Time - 12.00s\n",
            "Epoch [ 6/20] - Batch [  5100]: Loss - 0.94636, Score > -4.83834, Time - 12.00s\n",
            "Epoch [ 6/20] - Batch [  5200]: Loss - 0.92953, Score > -4.72326, Time - 11.95s\n",
            "Epoch [ 6/20] - Batch [  5300]: Loss - 0.92510, Score > -4.68211, Time - 11.95s\n",
            "Epoch [ 6/20] - Batch [  5400]: Loss - 0.92441, Score > -4.64699, Time - 11.95s\n",
            "Epoch [ 6/20] - Batch [  5500]: Loss - 0.94125, Score > -4.75462, Time - 11.95s\n",
            "Epoch [ 6/20] - Batch [  5600]: Loss - 0.93816, Score > -4.78266, Time - 11.99s\n",
            "Epoch [ 6/20] - Batch [  5700]: Loss - 0.93543, Score > -4.67481, Time - 12.02s\n",
            "Epoch [ 6/20] - Batch [  5800]: Loss - 0.94020, Score > -4.77656, Time - 12.05s\n",
            "Epoch [ 6/20] - Batch [  5900]: Loss - 0.94278, Score > -4.79468, Time - 12.01s\n",
            "Epoch [ 6/20] - Batch [  6000]: Loss - 0.93441, Score > -4.76030, Time - 11.99s\n",
            "Epoch [ 6/20] - Batch [  6100]: Loss - 0.93207, Score > -4.77773, Time - 12.06s\n",
            "Epoch [ 6/20] - Batch [  6200]: Loss - 0.93494, Score > -4.70600, Time - 12.06s\n",
            "Epoch [ 6/20] - Batch [  6300]: Loss - 0.92651, Score > -4.69158, Time - 12.12s\n",
            "Epoch [ 6/20] - Batch [  6400]: Loss - 0.92507, Score > -4.66095, Time - 12.06s\n",
            "Epoch [ 6/20] - Batch [  6500]: Loss - 0.93541, Score > -4.79202, Time - 12.07s\n",
            "Epoch [ 6/20] - Batch [  6600]: Loss - 0.93598, Score > -4.78838, Time - 12.06s\n",
            "Epoch [ 6/20] - Batch [  6700]: Loss - 0.93809, Score > -4.76609, Time - 12.06s\n",
            "Epoch [ 6/20] - Batch [  6800]: Loss - 0.93095, Score > -4.69674, Time - 12.07s\n",
            "Epoch [ 6/20] - Batch [  6900]: Loss - 0.93798, Score > -4.71520, Time - 12.04s\n",
            "Epoch [ 6/20] - Batch [  7000]: Loss - 0.93362, Score > -4.71984, Time - 11.95s\n",
            "Epoch [ 6/20] - Batch [  7100]: Loss - 0.92512, Score > -4.70194, Time - 11.96s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-6836f7986ff2>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mtotal_r2\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtotal_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoHCINJQKz-_",
        "outputId": "6cf2dc3f-5b37-4fc2-eaf8-8210c29cc252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "167022912"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(best_model, 'model.pth')"
      ],
      "metadata": {
        "id": "pfZNA8uKlmGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "b-nKppsalFBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_prompt = 'hello i am a language model and'"
      ],
      "metadata": {
        "id": "FLNwx-moqbBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_string(string, tokenizer, w2v, window_size=8) -> torch.Tensor:\n",
        "  tokens = tokenizer.encode(string).tokens[-window_size:]\n",
        "  if len(tokens) < window_size:\n",
        "    tokens = ['[PAD]'] * (window_size - len(tokens)) + tokens\n",
        "  tokens = torch.concat(tuple(map(lambda x: encode(x), tokens)))\n",
        "  return tokens\n",
        "\n",
        "prompt = encode_string(text_to_prompt, tokenizer, w2v, wnd_len)\n",
        "prompt.shape"
      ],
      "metadata": {
        "id": "Hu9Xwq-DWSwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d41e00b4-c63d-4d2d-c2dc-4a937378e103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([7680])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(M, prompt: str) -> str:\n",
        "  current = prompt\n",
        "  result = []\n",
        "  for _ in range(100):\n",
        "    y = M(current)\n",
        "    if decode(y) == '[EOF]': break\n",
        "    result.append(y)\n",
        "    current = torch.cat([current, y])[y.shape[0]:]\n",
        "  return tokenizer_decode([text_to_prompt + '|'] + list(map(lambda x: decode(x), result)))"
      ],
      "metadata": {
        "id": "nARlE8_5obHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to('cpu')\n",
        "best_model.to('cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etEk7d61qQKO",
        "outputId": "7c19631b-8c45-4a6f-932b-332697e224ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleModel(\n",
              "  (inp): Linear(in_features=7680, out_features=4096, bias=True)\n",
              "  (h): ModuleList(\n",
              "    (0-7): 8 x Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  )\n",
              "  (out): Linear(in_features=4096, out_features=320, bias=True)\n",
              "  (drop): Dropout(p=0.4, inplace=False)\n",
              "  (act): GELU(approximate='none')\n",
              "  (res_act): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval(best_model, prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "SHxpzVyDq-kL",
        "outputId": "e2fa99c2-df05-4a9b-f996-7a095c9842d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello i am a language model and| reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval(model, prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "Wvp6lbM8q7UP",
        "outputId": "8caa18f9-4c38-45f4-c217-34ba6524dd60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello i am a language model and| reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DMcv7kQZrHff"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}